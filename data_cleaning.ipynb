{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning\n",
    "\n",
    "1. Import Data\n",
    "\n",
    "Data Cleaning Steps:\n",
    "- export raw_combined_dataset\n",
    "- upload for team access\n",
    "- create filtered_combined_dataset\n",
    "    - identify unique id column(s?) ['id','url']\n",
    "    - add new from v6 to v5 with sql-join\n",
    "    - remove from v5 what is not in v6 ; for every row in v5 ...\n",
    "- export filtered_combined_dataset to be the \"work_data\" (newfile)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import Libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# identify path to raw data\n",
    "csvpath_v10 = Path('./raw_data/vehicles_v10.csv')\n",
    "csvpath_v9 = Path('./raw_data/vehicles_v9.csv')\n",
    "csvpath_v7 = Path('./raw_data/vehicles_v7.csv')\n",
    "csvpath_v6 = Path('./raw_data/vehicles_v6.csv')\n",
    "csvpath_v5 = Path('./raw_data/vehicles_v5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# load datasets into DataFrames\n",
    "vehicles_v10_df = pd.read_csv(csvpath_v10)\n",
    "vehicles_v9_df = pd.read_csv(csvpath_v9)\n",
    "vehicles_v7_df = pd.read_csv(csvpath_v7)\n",
    "vehicles_v6_df = pd.read_csv(csvpath_v6)\n",
    "vehicles_v5_df = pd.read_csv(csvpath_v5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "added_names_list = []       # list of the added column names\n",
    "combined_names_list = []    # list of all of the total column names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "original_column_names = vehicles_v5_df.columns.values\n",
    "combined_names_list.extend(vehicles_v5_df.columns.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# list of lists containing all subsequent versions column names\n",
    "subsequent_columns_lists = [\n",
    "    vehicles_v6_df.columns.values,\n",
    "    vehicles_v7_df.columns.values,\n",
    "    vehicles_v9_df.columns.values,\n",
    "    vehicles_v10_df.columns.values\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# generate list of column name changes\n",
    "for list in subsequent_columns_lists:\n",
    "    for name in list:\n",
    "        if name not in combined_names_list:\n",
    "            added_names_list.append(name)\n",
    "            combined_names_list.append(name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# sort lists of column name values\n",
    "original_column_names.sort()\n",
    "added_names_list.sort()\n",
    "combined_names_list.sort()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# print results\n",
    "print(f'ORIGINAL LIST:\\n{original_column_names}')\n",
    "print('----------------------------------------------------------------------------------------------------')\n",
    "print(f'ADDED COLUMNS LIST:\\n{added_names_list}')\n",
    "print('----------------------------------------------------------------------------------------------------')\n",
    "print(f'FINAL LIST:\\n{combined_names_list}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ORIGINAL LIST:\n",
      "['VIN' 'city' 'condition' 'cylinders' 'drive' 'fuel' 'image_url' 'lat'\n",
      " 'long' 'make' 'manufacturer' 'odometer' 'paint_color' 'price' 'size'\n",
      " 'title_status' 'transmission' 'type' 'url' 'year']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ADDED COLUMNS LIST:\n",
      "['city_url', 'county', 'desc', 'description', 'id', 'model', 'posting_date', 'region', 'region_url', 'state']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FINAL LIST:\n",
      "['VIN', 'city', 'city_url', 'condition', 'county', 'cylinders', 'desc', 'description', 'drive', 'fuel', 'id', 'image_url', 'lat', 'long', 'make', 'manufacturer', 'model', 'odometer', 'paint_color', 'posting_date', 'price', 'region', 'region_url', 'size', 'state', 'title_status', 'transmission', 'type', 'url', 'year']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# TODO: START HERE --- DOUBLE CHECK METHOD FOR CHECKING FOR DUPLICATES\n",
    "# check for duplicated values in the \"url\" column\n",
    "display(vehicles_v5_df.loc[:,'url'].duplicated().sum())\n",
    "display(vehicles_v6_df.loc[:,'url'].duplicated().sum())\n",
    "display(vehicles_v7_df.loc[:,'url'].duplicated().sum())\n",
    "display(vehicles_v9_df.loc[:,'url'].duplicated().sum())\n",
    "display(vehicles_v10_df.loc[:,'url'].duplicated().sum())\n",
    "\n",
    "print(vehicles_v5_df.loc[:,'url'])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "542860"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0         37.132840\n",
      "1         35.777999\n",
      "2         36.333900\n",
      "3         36.000092\n",
      "4         36.272932\n",
      "            ...    \n",
      "677807    61.288605\n",
      "677808    61.592300\n",
      "677809    61.190000\n",
      "677810    61.630300\n",
      "677811    61.546300\n",
      "Name: url, Length: 677812, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# concatenate all url's into a single list to verify appropriate unique identifier\n",
    "combined_url_df = pd.DataFrame()\n",
    "print(combined_url_df.dtypes)\n",
    "combined_url_df.append(vehicles_v5_df.loc[:,'url'], ignore_index= True)\n",
    "print(f'length: {len(combined_url_df.index)}')\n",
    "combined_url_df.append(vehicles_v6_df.loc[:,'url'], ignore_index= True)\n",
    "print(f'length: {len(combined_url_df.index)}')\n",
    "combined_url_df.append(vehicles_v7_df.loc[:,'url'], ignore_index= True)\n",
    "print(f'length: {len(combined_url_df.index)}')\n",
    "combined_url_df.append(vehicles_v9_df.loc[:,'url'], ignore_index= True)\n",
    "print(f'length: {len(combined_url_df.index)}')\n",
    "combined_url_df.append(vehicles_v10_df.loc[:,'url'], ignore_index= True)\n",
    "print(f'length: {len(combined_url_df.index)}')\n",
    "print(combined_url_df.dtypes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Series([], dtype: object)\n",
      "length: 0\n",
      "length: 0\n",
      "length: 0\n",
      "length: 0\n",
      "length: 0\n",
      "Series([], dtype: object)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# list column names of the DataFrame\n",
    "'''\n",
    "display('VERSION 5')\n",
    "display(vehicles_v5_df.columns)\n",
    "\n",
    "display('VERSION 6')\n",
    "display(vehicles_v6_df.columns)\n",
    "\n",
    "display('VERSION 7')\n",
    "display(vehicles_v7_df.columns)\n",
    "\n",
    "display('VERSION 9')\n",
    "display(vehicles_v9_df.columns)\n",
    "\n",
    "display('VERSION 10:')\n",
    "display(vehicles_v10_df.columns)\n",
    "'''\n",
    "\n",
    "original_columns_list = list(vehicles_v5_df.columns)\n",
    "\n",
    "subsequent_columns_dict = {\n",
    "    'v6': vehicles_v6_df.columns.values,\n",
    "    'v7': vehicles_v7_df.columns.values,\n",
    "    'v9': vehicles_v9_df.columns.values,\n",
    "    'v10': vehicles_v10_df.columns.values\n",
    "    }\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a3c2a51c84fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m '''\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0moriginal_columns_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicles_v5_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m subsequent_columns_dict = {\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "combined_columns_list = []  # create list to hold final list of column names for iterative comparison\n",
    "version_additions = []      # list of names to transfer to log in the changes list\n",
    "changes_list = []           # list of lists to hold changes associated with each progressive version"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add original column names to combined list\n",
    "combined_columns_list.extend(original_columns_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "for each column name in each version, determine if it is an addition over the previous version\n",
    "and make note if it is a new column name\n",
    "'''\n",
    "\n",
    "# add each column name not already appearing in a previous version\n",
    "# and associate with respective version entry\n",
    "for version, column_names in subsequent_columns_dict.items():\n",
    "    for name in column_names:\n",
    "        # print(f'{version}: {name}')\n",
    "        if name not in combined_columns_list:\n",
    "            # print(f'current iteration:\\n\\tlist: {version}\\n\\tvalue: {name}')\n",
    "            version_additions.append(name)\n",
    "            combined_columns_list.append(name)\n",
    "    changes_list.append([version,version_additions])\n",
    "\n",
    "# print(f'ORIGINAL LIST:\\n{original_columns_list}')\n",
    "for entry in changes_list:\n",
    "    print(f'Changes in VERSION: {entry[0]}\\n{entry[1]}')\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Changes in VERSION: v6\n",
      "[]\n",
      "Changes in VERSION: v7\n",
      "[]\n",
      "Changes in VERSION: v9\n",
      "[]\n",
      "Changes in VERSION: v10\n",
      "[]\n",
      "Changes in VERSION: v6\n",
      "[]\n",
      "Changes in VERSION: v7\n",
      "[]\n",
      "Changes in VERSION: v9\n",
      "[]\n",
      "Changes in VERSION: v10\n",
      "[]\n",
      "Changes in VERSION: v6\n",
      "[]\n",
      "Changes in VERSION: v7\n",
      "[]\n",
      "Changes in VERSION: v9\n",
      "[]\n",
      "Changes in VERSION: v10\n",
      "[]\n",
      "Changes in VERSION: v6\n",
      "[]\n",
      "Changes in VERSION: v7\n",
      "[]\n",
      "Changes in VERSION: v9\n",
      "[]\n",
      "Changes in VERSION: v10\n",
      "[]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop listings not containing posting_date/lat/long values\n",
    "# data sourcing, data review, and set up final working files"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# User Stories:\n",
    "- What should the project be about?\n",
    "    - first requirement (first 5 or so)\n",
    "- Data Analysis:\n",
    "    - what do we want to show?\n",
    "- Data Presentation:\n",
    "    - what viz do we want to see?\n",
    "        - together we decide--\n",
    "\n",
    "- also still need to pull data on interest rates/lending rates (if possible)\n",
    "    - need to know whether or not it's possible\n",
    "\n",
    "Acceptance Criteria:\n",
    "    - Used cars in West LA Example\n",
    "\n",
    "Specifically have only 4 or 5 high lievel items to present: Where are the opportunities?\n",
    "    should we be excited in the used car sales market in x place, yes or no??\n",
    "    Something of value has to come out of it\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('PyViz': conda)"
  },
  "interpreter": {
   "hash": "2cee6143c01626440da4de5fd7551af32d1b874c0d79c2a9f916ab53b14c1cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}